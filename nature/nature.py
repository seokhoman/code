import re
from konlpy.tag import Okt
import os
from sklearn.feature_extraction.text import TfidfVectorizer
from collections import defaultdict

# íŒŒì¼ ì´ë¦„ ì„¤ì •
input_file = "KakaoTalk_20250328_1853_34_224_group.txt"
output_file = "todo_list.txt"

# Okt í˜•íƒœì†Œ ë¶„ì„ê¸° ì´ˆê¸°í™”
okt = Okt()

def clean_message(line):
    """ì¹´ì¹´ì˜¤í†¡ ë©”ì‹œì§€ì—ì„œ ì´ë¦„, ì‹œê°„ ì •ë³´ ì œê±° + 'ì´ëª¨í‹°ì½˜' ë‹¨ì–´ë§Œ ì œê±°"""
    line = re.sub(r"\[\d{5} .*?\] \[.*?\] ", "", line)  # [ì´ë¦„] [ì‹œê°„] ì œê±°
    line = line.replace("ì´ëª¨í‹°ì½˜", "").strip()  # "ì´ëª¨í‹°ì½˜" ë‹¨ì–´ë§Œ ì œê±°
    return line


def extract_nouns(text):
    """ë¬¸ì¥ì—ì„œ ëª…ì‚¬ ì¶”ì¶œ"""
    words = okt.nouns(text)
    return " ".join([word for word in words if len(word) > 1])  # í•œ ê¸€ì ì œê±° í›„ ë„ì–´ì“°ê¸° êµ¬ë¶„

def is_schedule_related(sentence):
    """ì¼ì •ê³¼ ê´€ë ¨ëœ ë¬¸ì¥ì¸ì§€ íŒë‹¨"""
    schedule_keywords = ["ë‚´ì¼", "ëª¨ë ˆ", "ì‹œê°„", "ì¥ì†Œ", "ì–¸ì œ", "ì•½ì†", "ê³„íš", "ì¼ì •"]
    return any(keyword in sentence for keyword in schedule_keywords)

def process_chat_file(input_file, output_file):
    """ì¹´ì¹´ì˜¤í†¡ ëŒ€í™” íŒŒì¼ì„ ì²˜ë¦¬í•˜ì—¬ ë‚ ì§œë³„ ì¤‘ìš”í•œ í‚¤ì›Œë“œ + ì¼ì • ìš”ì•½ ì €ì¥"""
    if not os.path.exists(input_file):
        print(f"íŒŒì¼ {input_file}ì´(ê°€) ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    with open(input_file, "r", encoding="utf-8") as f:
        lines = f.readlines()

    chat_data = {}  # ë‚ ì§œë³„ ëŒ€í™” ì €ì¥
    schedule_summaries = defaultdict(list)  # ë‚ ì§œë³„ ì¼ì • ê´€ë ¨ ë¬¸ì¥ ì €ì¥
    current_date = None

    for line in lines:
        line = line.strip()
        if not line:
            continue

        # ë‚ ì§œ ê°ì§€ (ex: "--------------- 2025ë…„ 1ì›” 3ì¼ ê¸ˆìš”ì¼ ---------------")
        date_match = re.match(r"-+\s*(\d{4})ë…„ (\d{1,2})ì›” (\d{1,2})ì¼.*-+", line)
        if date_match:
            year, month, day = date_match.groups()
            current_date = f"{year}.{int(month):02}.{int(day):02}"
            chat_data[current_date] = []
            continue

        if current_date:
            # ë©”ì‹œì§€ í´ë¦¬ë‹ (ì´ëª¨í‹°ì½˜ ì œê±° í¬í•¨)
            text = clean_message(line)
            if text:
                chat_data[current_date].append(extract_nouns(text))
                
                # ì¼ì • ê´€ë ¨ ë¬¸ì¥ ì €ì¥
                if is_schedule_related(text):
                    schedule_summaries[current_date].append(text)

    # ë‚ ì§œë³„ í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ ë¬¸ì¥ìœ¼ë¡œ í•©ì¹¨
    date_texts = {date: " ".join(texts) for date, texts in chat_data.items()}

    # TF-IDF ê³„ì‚°
    vectorizer = TfidfVectorizer()
    tfidf_matrix = vectorizer.fit_transform(date_texts.values())
    feature_names = vectorizer.get_feature_names_out()

    # TF-IDF ì ìˆ˜ ê³„ì‚° í›„ ìƒìœ„ í‚¤ì›Œë“œ ì¶”ì¶œ
    important_keywords = {}
    for i, date in enumerate(date_texts.keys()):
        scores = tfidf_matrix[i].toarray().flatten()
        top_indices = scores.argsort()[-5:][::-1]  # ì ìˆ˜ê°€ ë†’ì€ ìƒìœ„ 5ê°œ ë‹¨ì–´ ì„ íƒ
        top_keywords = [feature_names[idx] for idx in top_indices if scores[idx] > 0]
        important_keywords[date] = top_keywords

    # ê²°ê³¼ ì €ì¥
    with open(output_file, "w", encoding="utf-8") as f:
        for date, keywords in sorted(important_keywords.items()):
            f.write(f"{date}: {', '.join(keywords)}\n")
            if schedule_summaries[date]:
                f.write(f"  ğŸ“Œ ì¼ì • ìš”ì•½: {schedule_summaries[date][0]}\n")  # ì²« ë²ˆì§¸ ì¼ì • ê´€ë ¨ ë¬¸ì¥ ì €ì¥

    print(f"ì¤‘ìš” í‚¤ì›Œë“œ ë° ì¼ì • ìš”ì•½ì´ {output_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

# ì‹¤í–‰
process_chat_file(input_file, output_file)
